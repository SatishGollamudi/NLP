{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  Sentiment Analysis with Fine-Tuned DistilBERT\n### Complete End-to-End Project on Google Colab\n\n**What we'll do:**\n1. Install dependencies & verify GPU\n2. Load & explore the IMDb dataset\n3. Tokenize text for DistilBERT\n4. Load pretrained model & add classifier head\n5. Train with HuggingFace Trainer API\n6. Evaluate with metrics + confusion matrix\n7. Save model to Google Drive\n8. Run predictions + interactive widget\n\n> â± Total runtime: ~10â€“15 minutes on T4 GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate scikit-learn -q\n",
        "print('âœ… All packages installed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Imports & GPU Check\n\nWe import all necessary libraries and verify that GPU is available.  \n`fp16=True` (mixed precision) only works on GPU â€” this speeds up training ~2x.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'GPU available: {torch.cuda.is_available()}')\n",
        "print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU â€” go to Runtime > Change runtime type > T4 GPU\"}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load & Explore Dataset\n\nWe use the **IMDb movie review dataset** â€” 50,000 reviews labeled POSITIVE/NEGATIVE.\n\nWe take a **subset** (3000 train / 750 test) for speed on the free Colab tier.  \nRemove `.select()` to train on the full dataset (~25 min, better accuracy).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "\n",
        "print('Loading IMDb dataset...')\n",
        "raw = load_dataset('imdb')\n",
        "\n",
        "# Subset for speed â€” remove .select() for full training\n",
        "train_data = raw['train'].shuffle(seed=42).select(range(3000))\n",
        "test_data  = raw['test'].shuffle(seed=42).select(range(750))\n",
        "\n",
        "dataset = DatasetDict({'train': train_data, 'test': test_data})\n",
        "\n",
        "print(f'Train: {len(dataset[\"train\"])} samples')\n",
        "print(f'Test:  {len(dataset[\"test\"])} samples')\n",
        "print(f'Labels: {set(dataset[\"train\"][\"label\"])}  (0=NEGATIVE, 1=POSITIVE)')\n",
        "\n",
        "# Check label balance\n",
        "labels = dataset['train']['label']\n",
        "pos = sum(labels)\n",
        "neg = len(labels) - pos\n",
        "print(f'\\nClass balance â€” POSITIVE: {pos} ({pos/len(labels):.0%}) | NEGATIVE: {neg} ({neg/len(labels):.0%})')\n",
        "\n",
        "# Show a sample\n",
        "print(f'\\nSample review (truncated):')\n",
        "print(dataset['train'][0]['text'][:300], '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Tokenize\n\nTokenization converts raw text â†’ numbers the model understands.\n\n- **`input_ids`**: token IDs (e.g. \"great\" â†’ 2307)\n- **`attention_mask`**: 1 for real tokens, 0 for padding\n- **`max_length=256`**: truncates/pads all sequences to same length\n\nDistilBERT uses **WordPiece tokenization** â€” unknown words are split into subwords.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Show what tokenization looks like\n",
        "example = 'This movie was absolutely fantastic!'\n",
        "tokens = tokenizer.tokenize(example)\n",
        "ids    = tokenizer.encode(example)\n",
        "print(f'Text:   {example}')\n",
        "print(f'Tokens: {tokens}')\n",
        "print(f'IDs:    {ids}')\n",
        "print()\n",
        "\n",
        "# Tokenize full dataset\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch['text'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "print('Tokenizing dataset...')\n",
        "tokenized = dataset.map(tokenize_fn, batched=True)\n",
        "tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "print('Done! Keys:', list(tokenized['train'][0].keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Load Pretrained Model\n\n`distilbert-base-uncased` is a **smaller, faster version of BERT**:\n- 40% fewer parameters than BERT (66M vs 110M)\n- 60% faster inference\n- Retains 97% of BERT's performance\n\nWe add a **classification head** on top â€” a fresh linear layer mapping from 768 dimensions â†’ 2 labels (POSITIVE / NEGATIVE).\n\nThe `MISSING` keys in the output are expected â€” that's the new classification head being randomly initialized (it will be trained).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    id2label={0: 'NEGATIVE', 1: 'POSITIVE'},\n",
        "    label2id={'NEGATIVE': 0, 'POSITIVE': 1},\n",
        "    ignore_mismatched_sizes=True  # suppresses the size mismatch warning\n",
        ")\n",
        "\n",
        "total     = sum(p.numel() for p in model.parameters())\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Total parameters:     {total:,}')\n",
        "print(f'Trainable parameters: {trainable:,}')\n",
        "print(f'Model architecture:\\n{model.__class__.__name__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Define Metrics\n\nWe track two metrics:\n- **Accuracy**: % of correct predictions\n- **F1 Score**: harmonic mean of precision & recall â€” better for imbalanced datasets\n\nWe use F1 as the metric to pick the best checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "accuracy_metric = evaluate.load('accuracy')\n",
        "f1_metric       = evaluate.load('f1')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        **accuracy_metric.compute(predictions=preds, references=labels),\n",
        "        **f1_metric.compute(predictions=preds, references=labels)\n",
        "    }\n",
        "\n",
        "print('âœ… Metrics defined: accuracy + F1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Configure Training Arguments\n\nKey hyperparameter choices:\n\n| Parameter | Value | Why |\n|---|---|---|\n| `learning_rate` | 2e-5 | Small â€” we nudge pretrained weights, not retrain |\n| `epochs` | 3 | Usually 2â€“4 is enough for fine-tuning |\n| `warmup_steps` | 56 | Gradually ramps up LR at start to avoid instability |\n| `weight_decay` | 0.01 | L2 regularization to reduce overfitting |\n| `fp16` | auto | Mixed precision on GPU = faster + less memory |\n| `load_best_model_at_end` | True | Restores best checkpoint after training |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=56,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_strategy='steps',\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    seed=42,\n",
        "    report_to='none'\n",
        ")\n",
        "print('âœ… Training arguments configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Train! ðŸš€\n\nThis is the core step. The Trainer handles:\n- Forward pass â†’ compute loss\n- Backward pass â†’ compute gradients (backprop)\n- Optimizer step â†’ update weights\n- Evaluation after each epoch\n\n**Expected time: ~8â€“12 minutes on T4 GPU**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized['train'],\n",
        "    eval_dataset=tokenized['test'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "print('Starting training...')\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(f'\\nâœ… Training complete!')\n",
        "print(f'Total train time: {train_result.metrics[\"train_runtime\"]:.1f}s')\n",
        "print(f'Samples/second:   {train_result.metrics[\"train_samples_per_second\"]:.1f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Evaluate Model\n\nWe run a full evaluation including:\n- Final metrics (accuracy, F1, loss)\n- Classification report (precision, recall per class)\n- Confusion matrix visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "# Final metrics\n",
        "results = trainer.evaluate()\n",
        "print('Final Evaluation Results:')\n",
        "print(f'  Accuracy: {results[\"eval_accuracy\"]:.4f}')\n",
        "print(f'  F1 Score: {results[\"eval_f1\"]:.4f}')\n",
        "print(f'  Loss:     {results[\"eval_loss\"]:.4f}')\n",
        "\n",
        "# Full inference loop for classification report\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "for i in range(0, len(tokenized['test']), 32):\n",
        "    batch = tokenized['test'][i:i+32]\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'].to(device),\n",
        "            attention_mask=batch['attention_mask'].to(device)\n",
        "        )\n",
        "    all_preds.extend(torch.argmax(outputs.logits, dim=-1).cpu().tolist())\n",
        "    all_labels.extend(batch['label'].tolist())\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(all_labels, all_preds, target_names=['NEGATIVE', 'POSITIVE']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['NEGATIVE', 'POSITIVE'],\n",
        "            yticklabels=['NEGATIVE', 'POSITIVE'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Training loss curve\n",
        "log_history = trainer.state.log_history\n",
        "train_losses = [(x['step'], x['loss']) for x in log_history if 'loss' in x]\n",
        "if train_losses:\n",
        "    steps, losses = zip(*train_losses)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(steps, losses, marker='o', markersize=3, linewidth=1.5, color='royalblue')\n",
        "    plt.title('Training Loss Curve')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Save Model to Google Drive\n\n**Important!** Colab resets after ~90 min of inactivity â€” your model will be lost.  \nAlways save to Google Drive so you can reload it in a new session.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/sentiment_model'\n",
        "trainer.save_model(MODEL_SAVE_PATH)\n",
        "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
        "print(f'âœ… Model saved to Google Drive: {MODEL_SAVE_PATH}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Load & Run Predictions\n\nWe use the `pipeline` API â€” the simplest way to use any HuggingFace model.  \nIf you're in a new Colab session, just run this cell (and mount Drive first).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/sentiment_model'\n",
        "\n",
        "classifier = pipeline(\n",
        "    'text-classification',\n",
        "    model=MODEL_SAVE_PATH,\n",
        "    return_all_scores=True,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "test_sentences = [\n",
        "    'This movie was absolutely fantastic, I loved every minute!',\n",
        "    'Terrible film. Boring, predictable and poorly acted.',\n",
        "    'It was okay, not great but not terrible either.',\n",
        "    'One of the best performances I\\'ve seen in years.',\n",
        "    'Complete waste of time and money.',\n",
        "    'A beautiful story with stunning visuals.',\n",
        "    'I fell asleep halfway through, so dull.'\n",
        "]\n",
        "\n",
        "print('Predictions:\\n')\n",
        "for text in test_sentences:\n",
        "    all_scores = classifier(text)\n",
        "    scores = {r['label']: r['score'] for r in all_scores}\n",
        "    label  = max(scores, key=scores.get)\n",
        "    conf   = scores[label]\n",
        "    emoji  = 'ðŸ˜Š' if label == 'POSITIVE' else 'ðŸ˜ž'\n",
        "    bar_pos = 'â–ˆ' * int(scores['POSITIVE'] * 20)\n",
        "    bar_neg = 'â–ˆ' * int(scores['NEGATIVE'] * 20)\n",
        "    print(f'{emoji} [{label} â€” {conf:.1%}]  {text[:60]}')\n",
        "    print(f'   POS [{bar_pos:<20}] {scores[\"POSITIVE\"]:.1%}')\n",
        "    print(f'   NEG [{bar_neg:<20}] {scores[\"NEGATIVE\"]:.1%}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Interactive Demo Widget\n\nType any text and click **Analyze** to see the model's prediction live!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": ""
      },
      "outputs": [],
      "source": [
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "text_input = widgets.Textarea(\n",
        "    placeholder='Type any sentence or movie review here...',\n",
        "    layout=widgets.Layout(width='600px', height='100px')\n",
        ")\n",
        "button = widgets.Button(\n",
        "    description='Analyze Sentiment',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='200px')\n",
        ")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_click(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        text = text_input.value.strip()\n",
        "        if not text:\n",
        "            print('âš ï¸ Please enter some text!')\n",
        "            return\n",
        "        all_scores = classifier(text)\n",
        "        scores = {r['label']: r['score'] for r in all_scores}\n",
        "        label  = max(scores, key=scores.get)\n",
        "        conf   = scores[label]\n",
        "        emoji  = 'ðŸ˜Š' if label == 'POSITIVE' else 'ðŸ˜ž'\n",
        "        print(f'\\nResult: {emoji} {label}')\n",
        "        print(f'Confidence: {conf:.1%}')\n",
        "        print(f'  POSITIVE: {scores.get(\"POSITIVE\", 0.0):.1%}')\n",
        "        print(f'  NEGATIVE: {scores.get(\"NEGATIVE\", 0.0):.1%}')\n",
        "\n",
        "button.on_click(on_click)\n",
        "display(text_input, button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ‰ You're Done!\n\n### What you built:\n- Fine-tuned **DistilBERT** (66M parameters) on IMDb reviews\n- Achieved **~88% accuracy** with just 3000 training examples\n- Saved the model to Google Drive for reuse\n- Built an interactive prediction widget\n\n---\n\n### Next Steps to Level Up:\n\n**1. Train on full dataset** â€” Remove `.select()` in Cell 3 â†’ expect ~93% accuracy\n\n**2. Try a stronger model** â€” Change `MODEL_NAME`:\n```python\nMODEL_NAME = 'roberta-base'          # better accuracy\nMODEL_NAME = 'bert-base-uncased'     # original BERT\nMODEL_NAME = 'distilroberta-base'    # fast + accurate\n```\n\n**3. Try LoRA (fine-tune large models cheaply)**\n```python\n!pip install peft\nfrom peft import get_peft_model, LoraConfig\n```\n\n**4. Push model to HuggingFace Hub**\n```python\ntrainer.push_to_hub('your-username/my-sentiment-model')\n```\n\n**5. Try other tasks** â€” Just change the dataset and `num_labels`:\n- Named Entity Recognition (NER)\n- Question Answering\n- Text Summarization\n- Multi-class classification (3+ labels)\n"
      ]
    }
  ]
}